{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 4 - Getting started with neural networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrahyurtlu/Intro-to-tensorflow-for-deep-learning/blob/main/CMPE430/Lab_4_Getting_started_with_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVMuSb4a3rhz"
      },
      "source": [
        "#**CMPE430 LAB WEEK 4 - Getting started with neural networks**\n",
        "\n",
        "11.11.2021 Thursday 14:30-16:20\n",
        "\n",
        "Lab Assistant : Cansen Çağlayan (cansen.caglayan@atilim.edu.tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdWWswGD32Ge"
      },
      "source": [
        "**References**\n",
        "\n",
        "Book : Deep Learning with Python, François Chollet\n",
        "\n",
        "https://www.tensorflow.org/tutorials/keras/classification#compile_the_model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePHJk5IGKdhN"
      },
      "source": [
        "##**2.3 The gears of neural networks: tensor operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBvrO8mdLdKQ"
      },
      "source": [
        "A Keras layer instance looks like this:\n",
        "\n",
        "**keras.layers.Dense(512, activation='relu')**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9pr54IxLjHd"
      },
      "source": [
        "This layer can be interpreted as a function, which takes as input a 2D tensor and returns another 2D tensor—a new representation for the input tensor. \n",
        "\n",
        "Specifically, the function is as follows (where W is a 2D tensor and b is a vector, both attributes of the layer):\n",
        "\n",
        "**output = relu(dot(W, input) + b)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdlXhkH0OLLQ"
      },
      "source": [
        "We have three tensor operations here: \n",
        "\n",
        "1. a **dot product (dot)** between\n",
        "the input tensor and a tensor named W; \n",
        "2. an **addition (+)** between the resulting 2D tensor and a vector b; \n",
        "3. a **relu operation**. relu(x) is max(x, 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJG2aw_celZC"
      },
      "source": [
        "**2.3.1 Element-wise operations**\n",
        "\n",
        "The relu operation and addition are element-wise operations: operations that are\n",
        "applied independently to each entry in the tensors being considered. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXjjgPHqenBD"
      },
      "source": [
        "If you want to write a naive Python implementation of an element-wise operation, you use a for loop, as in this naive implementation of an element-wise relu operation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvt1OFjJez-W"
      },
      "source": [
        "def naive_relu(x):\n",
        "    len(x.shape) == 2 #x is a 2D Numpy tensor.\n",
        "    x = x.copy() #Avoid overwriting the input tensor.\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYa_A0mSfCxu"
      },
      "source": [
        "You do the same for addition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHgRwmbafB3M"
      },
      "source": [
        "def naive_add(x, y):\n",
        "    len(x.shape) == 2\n",
        "    x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZS8n52GlGYt"
      },
      "source": [
        "#z=x+y #Element-wise addition\n",
        "#z = np.maximum(z, 0.) #Element-wise relu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeNXqh1yjuHK"
      },
      "source": [
        "**2.3.2 Broadcasting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwxYi6Jmj5ti"
      },
      "source": [
        "What happens with addition when the shapes of the two tensors\n",
        "being added differ?\n",
        "\n",
        "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to match the shape of the larger tensor.\n",
        "\n",
        "Broadcasting consists of two steps:\n",
        "\n",
        "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
        "\n",
        "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8vQ-AX_jv-1"
      },
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    len(x.shape) == 2\n",
        "    len(y.shape) == 1\n",
        "    x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN5kO08fuJZ-"
      },
      "source": [
        "The following example applies the element-wise maximum operation to two tensors\n",
        "of different shapes via broadcasting :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM71LnCzt6N-"
      },
      "source": [
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))  #x is a random tensor with shape (64, 3, 32, 10).\n",
        "y = np.random.random((32, 10)) #y is a random tensor with shape (32, 10).\n",
        "z = np.maximum(x, y) #The output z has shape (64, 3, 32, 10) like x."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnhG5reCkqzE"
      },
      "source": [
        "**2.3.3 Tensor dot**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daxE7ZwyuQzD"
      },
      "source": [
        "The dot operation, also called a tensor product (not to be confused with an element-wise product) is the most common, most useful tensor operation. Contrary to element-wise operations, it combines entries in the input tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLIU448hkr2w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "013uepDJi6aN"
      },
      "source": [
        "**2.3.4 Tensor reshaping**\n",
        "\n",
        "Reshaping a tensor means rearranging its rows and columns to match a target shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0K3se1Ti_S6"
      },
      "source": [
        "# Example : train_images = train_images.reshape((60000, 28 * 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeg3SjYYjKPs",
        "outputId": "be397477-dba6-458c-a2c4-8130b2984160"
      },
      "source": [
        "x = np.array([[0., 1.],\n",
        "             [2., 3.],\n",
        "             [4., 5.]])\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF0JMmH7jNlK",
        "outputId": "722fcdac-05c1-41ec-b56d-0016773800ab"
      },
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KmMnOXjjW2U",
        "outputId": "f3ac03a8-099c-4ce9-c5ad-b4804fa93747"
      },
      "source": [
        "x = x.reshape((2, 3))\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 2.],\n",
              "       [3., 4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls4_HW0VjbgP"
      },
      "source": [
        "A special case of reshaping that’s commonly encountered is **transposition.** Transposing a matrix means exchanging its rows and its columns, so that x[i, :] becomes x[:,i]:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZRMji7NjRC-",
        "outputId": "b30d9d68-5296-4d49-fd64-6da8f356f789"
      },
      "source": [
        "x = np.zeros((300, 20))\n",
        "x.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54GuPc19jkL6",
        "outputId": "f3cba97e-73c7-4d9c-c4ea-4062d19fbf3e"
      },
      "source": [
        "x = np.transpose(x)\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mudI0b4kyfOe"
      },
      "source": [
        "#Looking Back at Our First Neural Network Example (Classification with MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUoAFhZhwVyR"
      },
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import models, layers, optimizers, losses, metrics\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhH6_pLgz13w"
      },
      "source": [
        "#Load the Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GpBlWV38z_x",
        "outputId": "e13122ce-0da5-44e9-b095-6f7170f424a5"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUU-ckp_838F",
        "outputId": "e9d53f31-f334-434b-d7f3-ca6aef5f1159"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkJM_owFzukM"
      },
      "source": [
        "Before training, we’ll preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the [0, 1] interval. \n",
        "\n",
        "Previously, our training images, for instance, were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83KN1QrN8Qxp"
      },
      "source": [
        "We know that the pixel values for each image in the dataset are unsigned integers in the range between black and white, or 0 and 255.\n",
        "\n",
        "A good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu2YjB1o8WuJ"
      },
      "source": [
        "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the training set and the testing set be preprocessed in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWWtBpAj3rJC"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ldJ3NBxe0b"
      },
      "source": [
        "The input images are stored in Numpy tensors, which are\n",
        "here formatted as float32 tensors of shape (60000, 784) (training data) and (10000,784) (test data), respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7BtSkO03Cd6",
        "outputId": "76a5ba11-83e7-4797-8bd0-f75b0d0dd268"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7RuvH9_3FRv",
        "outputId": "d3ec8775-18b4-4927-e7f2-7d8b0ea91868"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OnBJIDT0ANQ"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61vPYjYry9Ah"
      },
      "source": [
        "-- The core building block of neural networks is the **layer**, a data-processing module that you can think of as a filter for data. Some data goes in, and it comes out in a more useful form. Specifically, layers extract representations out of the data fed into them—hopefully, representations that are more meaningful for the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h0S2rBUzPE2"
      },
      "source": [
        "-- Here, our network consists of a sequence of two Dense layers, which are densely connected (**also called fully connected**) neural layers. The second (and last) layer is a **10-way softmax layer**, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNx_mjq8wDt7"
      },
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blFGDvA5xpI_"
      },
      "source": [
        "This network consists of a chain of two Dense layers, that each layer applies a few simple tensor operations to the input data, and that these operations involve weight tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtnDXGDgAxzj"
      },
      "source": [
        "**Activation Function :** It’s a function that you use to get the output of node.\n",
        "\n",
        "units: Positive integer, dimensionality of the output space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFK-FGSe0D4z"
      },
      "source": [
        "##Compilation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSvs8nWgzcW0"
      },
      "source": [
        "To make the network ready for training, we need to pick three more things, as part of the compilation step:\n",
        "\n",
        "- **A loss function**—How the network will be able to measure its performance on\n",
        "the training data, and thus how it will be able to steer itself in the right direction.\n",
        "\n",
        "- **An optimizer**—The mechanism through which the network will update itself\n",
        "based on the data it sees and its loss function.\n",
        "\n",
        "- **Metrics** to monitor during training and testing—Here, we’ll only care about **accuracy** (the fraction of the images that were correctly classified)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7kyha42IFSS"
      },
      "source": [
        "**Accuracy** measures how close a given value is to the truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwu_z57dIHMN"
      },
      "source": [
        "![foto.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGNhbnNlbiBjYW5zZW4AAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzczAACSkgACAAAAAzczAADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjExOjExIDExOjMyOjM5ADIwMjE6MTE6MTEgMTE6MzI6MzkAAABjAGEAbgBzAGUAbgAgAGMAYQBuAHMAZQBuAAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjEtMTEtMTFUMTE6MzI6MzkuNzI2PC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPmNhbnNlbiBjYW5zZW48L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgAUAGaAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKiS7t5LuW1jnie4hVWlhVwXjDZ2kjqAdpxnrg+lS0AFFFFABRRRQAUUUUAFFFFABRRRQAVwfjjVvEnh3VrfUdHuXvbGOOS7u9MMKZMEZiV/LYLu3fvC3J7Y9q7yuU1HxDpEHxG07T7i+hW4+x3EDRHs8j25RT2BYA4B60ARXWqXup6poVxoWuBdL1hJNojt0YqBCzB1Y553AZBB6EV0A1/RzFcyjVrEx2hC3D/aUxCScAMc/Lk8c964DStBvfCnxPsdIt4y3h+4luL6wI6WrmNhLD9CWVl9s9ecPupdO0LxN44hv2trL+0re2NlE2FN03lMn7ternfgcA84oA7w6/o6rbFtWsQLtQ1uTcp++B6FOfmH0pg8SaG1o10us6ebdH8tpRdJsD4ztJzjOOcV47PqWh3fw5+G1vcT2szWmo2Zu0bB8uNYm37/8AZBZc545FdNp2r6DH8ZPE97dXNqI/sEEYlfGCV3CUZ9gFB+gpgbnjvW9R0eTw5faVqaRWd3q1raXEZiR0likb5m3nkcDqPf8ADp9N1jTNZhaXSNRtL+NDtZ7WdZQp9CVJrxqG8trv4N+BUc/aBZazZLeRbC5jVCzOGXBOAgzjHSug1eSTxP48nuvAl3DcbdAura5vbVw0TSt/qE8xTtLBst1OBnpmkB6BH4g0aa6ntYdXsZLi2VmniW5QvEF6lhnIA75otfEWi311HbWWsWFxcSqWjiiuUd3A6kAHJArzTw4ujtZeFo7rU7hb/R12yaWkCK9mBEyzCbIDCL73zH7x24yTg6Xw0g8P6hLqUiJaT3tvrd9d2h2jfDE0hVWX0Ug8DpzmgD0W5ureytpLm8njt4IxueWVwqqPUk8Cs+48SaWnh+71e1v7S6tbZGJkjuFKFgOE3DIBJIH4iuc+IUM/9teFL2dWbR7PUjJf4UssfyERu4/uhu54GR0rHu7+C88WeKNasp4z4fbQo7eS76w3F3vfYUf7rEAhcjOMryKANvwBqOsa7BDrV54gtL+yvLGOR7CCNM2c7YYruUZwFIGGJOc101/r2kaXOkOp6rZWcsgyiXFwkbMM4yASM88Vz/wsltZfhtowtmjaWGzihuNmMq6oPlb3AI47Vzdp/Y9prHjXTvHqxtcanfeZbxykq99a7F8qOLnLlSpG1T17CgD0XUdb0rR/L/tfU7Ox804j+0zrHv8ApuIzRd63pVhKkV9qdnbSOnmKk1wiFl/vAE9ODz7VxWn39tonjrxNdeKttlFew2xsHulADwCPDQIeQWD5ygJJLZwc1yMUkVj4X8DW/iTy7O6i1n7SLe4XbLbWOJ9ivnov3Rj6DHFAHro8TaCVhYa3pxE8ZliP2tP3iDOWXnkDa3I4+U+lSTa9o9tpseoXGq2MVlKcR3L3CLG/0YnB6GvOvGMXhqw8SeBoIFsraxt7uS8ZAAqpGyO6uc/wl8/ial1vSbfw18QtJuROuh+HodKltbW4EatBbTtLudW3AhNy/wARx90jNAHo0uq6fBpo1Ga+to7EqGFy8yiPaeh3ZxisPxL430vQ/DQ1W3vrO5EsqRW4WdSsrF1U4IPOM5OOmK4NbS30fUvB9/HPc3PhO0v755Lq5QJFE8iny5SOgiDFwrEADOehBOl4zg0m6+H+o3fhm1DWzavBdz3cXzRzkzRtLKjZOVGBkjjKn0NMD0q0vLa/tUubG4iuYHztlhcOrYODgjg8giqD+KfD8Zl8zXNNXyWCy5u4x5bEkANzwSQRz6GnaBqlvq2nPcWUSx2y3EsUTJ9yRUcrvU4AIOCQRke5rhNMu9B0b4s+OH1c2dpF9lsVVpkCrtMb71Bxj5uPl6tjocUgPQLrW9KsPK+3anZ23njdF51wqeYPVcnn8KRtd0hNIXVW1SyGnMMi8NwnkkZx9/OOvHWvGYYLbT/AXhO012P7JnXluYYLsfvI7HzXIDZ/hwRkccMOK6XxFZQaR4p8Nappeyw8NkXMz3tvEHit55gCszAggBhlQxGBuPIzQB6OmpWMmnf2hHeW72W0v9pWVTHtHfdnGK43SvFZufiVeWkXiG31DQxpB1BXTyvKhPnFD+8XqFCnqe/PtzmoadZWUGmX9pcXGoeHf+Ei+3X85jU27bouJFCcGISYJOMbskcDNXR4i0BPjpcXX2y3NrceHUQzquY5WEzsTuAww2DrnHykZ4xQB2/h3Uribw0t7reo6XcSKZDLc6fLm3Chjj5iey4z75qDVPG+hWXhrUNXtdW0+7jsomY+VdI4Z9pZU4PVscDrXl0couvA1iLE/abHTvFbXeqW8A3EWhuZGV2UdU4DY9BnoM11viQaJrvhPxlP4Ut1v7m603M19aESRTusbqqKwJBdVHIXoGGetMDcv/FH2nwONT0XWNEtbyQRqst/cA28chAZ42IOdwXdx16VvX+q6fpMKS6rf2tmjnar3Eqxqx9AWNeYeKNb07UPgpq9tbrDiK2ht4ZUIK3E5hRyFOMFgMg4JPBHtWmmp2dv8V38QandxLo1xpCxadfStiBXEh8xA54Vjx6Fh0zikB3T61pca2rSalaKLz/j2JnUef0+5z83UdPUUafrOmat539lajaXvkNsl+zTrJ5bejbScH2NeMa0RB8Pb/7ci20V/wCJjdaTBNHsf7N9ojLOoPRTy3QcNnoa29Y8Q6NbfEa7khuE/s5/CkkTJbt5fmOHDRopA4by2JU+hyKAPSLDxFouqXT22maxYXk8ed8VvcpIy465AORWjXlPgma5i8YaVYw65ZeJLCCxljRxbiG70xRsAjlCHAzgLhgGyOnBr1agAooooAKKKKACgnAyeBRWJ4tt9dvfD1xZ+GhZC6uUaJpbyd4xErAjcu1Gyfy/pQB5/pt9caZ8U9K8RzsxsfGMcttgnKx7GzbMP96ML+LH616BrfiI6ZqVjpVhai91S/DtDA0vloqIMs7vg7VGQOASSenXHJeJvhqt54esP+EX8P8Ah/Sdct54bj7TEfKELoQcB1h3SA8jnb2PbFa+p6Drt1rmi+J7aOyi1WwSW3ubAXLNDNC56LL5YIYYDcpjPHvTAk/4TiWPS7E3WiXNvq9/ePZ2+nSNt8x0Jy4dgP3e0bt23p0FVtQ8d6ppPh6/1LUPC80b6fdfZ5lFxiNwdoWSN3RS6EsBkL2PWn6v4c17VzpWsvNZw61pV69xBaq7GAxMuwwmTaGyV53beCSMYwan1vQtb8UeEtY0/UZLSzmu9v2SGNzKkQQhgXfapJZhzgYAxjPJKAtXfie5tvGC6Cuks7TWct1bT/aFAm2bcrjHync+Mn61R0Hxxea5qS26eHbmOBb24sbm5WZXW3lizncAOhIxkccj3xBLpXim58e6d4gax01IraymtXtjfucb3U7wwi5Py/d2jGB8xzgT+DtC8Q6TZaza6uun25v725vYZ7K5eVo2mYttKtGo+XPXPPoKAC28dTrcaZ/bOiyaXb6tdtaWpmm/fK/z7fMiKgpu2cYLDkZIzS6h44uBd6vD4e0SXV/7FwLwrKULORny4lCsZHA7cDnrXI/8K28RrbaRFb2uhx32l3i3s2ryTu0+oSjIG4+XlRhiTktyqgcc102l+G/EHhjWNTn0k2OoxauyTzvdStC0NwFCu+1UIZWwW2jbzxnHIYF5vGFxH4xtdAm0aWJr22kuLaeSdQJFQAldvUNkjjt17Vf8La9ceI9J+3zaY1hE7HyN06yecoON4K9jjj1HNcn43ht/EQ03S9O1df8AhItN1CGB5UTa48yM+dgdOYizkDIGBXoNrbQ2VnDa2saxQQIscaKOFUDAA/AUgM6+8QQ2F49u9hqczJj57exkkQ5GeGUYNMg8SwXEyRrp2rIXYLuk0+VVGe5JHA96W/8AD3269kuP7X1W234/dW9zsRcADgY46ZqO38MfZ7mKb+29Zl8tw2yS7yrYOcEY5FAG5Wf/AG9o/wD0FbH/AMCU/wAa0Kyv+EV8Pf8AQB0z/wAA4/8ACgCX+39H/wCgrY/+BKf40f29o/8A0FbH/wACU/xrltRuPDVlqOoWdv4IN+2nRiS5ktrG2EaAruxudlBO05x1qjpuveFNRt9Kuv8AhBJrax1aVIrW8msLUxlmOF3bHYrk8cgc0Adv/b2j/wDQVsf/AAJT/Gj+3tH/AOgrY/8AgSn+NRf8Ir4e/wCgDpn/AIBx/wCFQNoHhdL6KzbRtKFxLG8qR/Y48siFQx6di6/nQBc/t/R/+grY/wDgSn+NH9vaP/0FbH/wJT/Gov8AhFfD3/QB0z/wDj/wrD1pPDWiazpWn3HhK3kGqTi3huo7ODykkIJ2tk7gdqk8KR70AdD/AG9o/wD0FbH/AMCU/wAaP7e0f/oK2P8A4Ep/jUX/AAivh7/oA6Z/4Bx/4Uf8Ir4e/wCgDpn/AIBx/wCFAEv9v6P/ANBWx/8AAlP8aP7e0f8A6Ctj/wCBKf41F/wivh7/AKAOmf8AgHH/AIUf8Ir4e/6AOmf+Acf+FAEv9vaP/wBBWx/8CU/xo/t7R/8AoK2P/gSn+NRf8Ir4e/6AOmf+Acf+FYXiEeGPDl1pcV14Tt5o9SvI7NJ4bODZFJIwVQ+SG7k8A9DQB0X9vaP/ANBWx/8AAlP8aP7e0f8A6Ctj/wCBKf41F/wivh7/AKAOmf8AgHH/AIUf8Ir4e/6AOmf+Acf+FAEv9vaP/wBBWx/8CU/xo/t7R/8AoK2P/gSn+NRf8Ir4e/6AOmf+Acf+FH/CK+Hv+gDpn/gHH/hQBL/b2j/9BWx/8CU/xo/t7R/+grY/+BKf41Xl8NeG4IXlm0TS0jjUszG0jwoHJPSsHw+3hzxFdBbfwYlvay2iXdvdz6fEI5kZiBgjOCQA2OuGBOOlAHTf29o//QVsf/AlP8a5bR7G20vxlqWvSeMLC5GpiNbi3KRrkRqyx4YPwRu5459q6T/hFfD3/QB0z/wDj/wo/wCEV8Pf9AHTP/AOP/CgCX+3tH/6Ctj/AOBKf40f29o//QVsf/AlP8ai/wCEV8Pf9AHTP/AOP/Cj/hFfD3/QB0z/AMA4/wDCgCX+3tH/AOgrY/8AgSn+NH9vaP8A9BWx/wDAlP8AGueto/DU/jK48Ov4Rgt7iG1+1CeWzg8uWPcFBTaSepPUA8Va0Gx8J+I9Ij1LTtAshbyO6L5+nLG3ysVPysuRyKANf+3tH/6Ctj/4Ep/jR/b2j/8AQVsf/AlP8arzeG/DdvBJNNomlpHGpd2NnHgADJPSsvU4vBuleGxrs+h2ctiUjkVoNMDsyuRtO0Ln+IUAbn9vaP8A9BWx/wDAlP8AGj+3tH/6Ctj/AOBKf41Cvhfw8yhhoOm4IyM2SA/ltpf+EV8Pf9AHTP8AwDj/AMKAJf7e0f8A6Ctj/wCBKf40f29o/wD0FbH/AMCU/wAai/4RXw9/0AdM/wDAOP8Awo/4RXw9/wBAHTP/AADj/wAKAJf7e0f/AKCtj/4Ep/jWhWV/wi3h8dNC0z/wDj/wrVoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAKi6Vpyaq2ppYWq6g8fltdiFfNZOPlL4zjgcZ7VboooAKKKKACiiigDI1iyt7XQddmgiCSXcEks7ZPzsIQgP/fKKPwrA+GVnBffCHw5HdR+YiQxyqMkYdJN6nj0ZQa6TWdEj1qJYp7y8t4grK6W03liUMACG9en6moPD/hez8M26W2mT3n2SOPy4raacyRxjOflB6UAcSviTWb74a3vjuPVJ7SW3a5mg0/y08gxxSsgjkBXcSdnJDA5bjHSoTJLe/F601SXXr7TLaXwudQfLQbLePzoyyZeMgJgZJPzcfeA4rr7jwFo1w8yH7SlhcT/aJ9NSYi2mkyCSyehIyVBCk8kGrGr+DtK1nU4L66WVJI7Z7N1hfas9u+N0TjunHTigDlPE/iHUYfEOu/2Tq17MdNs0ZbXTraMx2j7HYtcPL8pBwDtU7sDgZ6yaxrH9vaR8PNTfy0mu9WtJ5YkbIjZ7SRyv/jw/Aiuku/BWl3eo312XuoRqOz7dBDOUjutgAG8degwQCNw4ORWefhhoIgsooZdRgFiyPbmK7ZSjooRX92CBUyf4VFAGz4te6h8IapcafezWVxb2sk8c0KozAopbGHVhg4weM46Eda4/S9Q17T28E3l9rlxff26RHeW0kUYjXdbGRSmF3Agr3Jzk+2O61jSoda0ySwupZ44ZRiTyJNhde6k+hHBFYI+HemrFYRjUNW26cB9jzeE+RhSgK8ddpK89vfmgDLt7vWlv/G+nvr97IdNigltLgxQb4sxtIVx5ewg4xypOO+eayptd8QN4M+H+pW+tzxXGr3dta3gMUbJJ5qOzPyudwI4AIX2rt9Q8I2d9qVzeJdXlo16iJex27qFulUEKHypPQ4+UjI4PFZo+GmkDTdPsPt2q/Z9MlWazX7Yf3DqMKRx2GQPqaAKWny6zdePde8Otr94LSztre5hl8uIzBpAwI3bMFcrnGM54zjg8/r2qX/ij4XeBNQubj7Pf3utWG64iRfkkLsN4UgrnPOCMe2K7hPA9jHrN7qsWoapHeXyeXNIt0eVGdoHHG3JxTIfh7osXh6z0QteyWNlci5t0a6YNEyghQrjDKBnIwQQec0AYuq+ItS8F+I5LCW9udagm0e6v0+1KnmRywjcRmNFG1h2xwenpUHhrVPGGpJoOoNFqLWmoxb9QlnazWGMSJlHgCuX+ViAAwOQeRmuu07wpY2N+9/cTXOpXz2/2U3N9IHYQ5zsAACgZ6nGT3JqvbeB9Ns1WK3uL9baHebW2+0nyrVmBG6NexGTtzkL/AAgUAYfgZfEWp315e33iS4nt7DVryya2mt4iLiKNiqMSqrtfOMkDHyjAGTnW8Xa9eafrXh3RrA+S2s3jRS3OMtFGiF22543HAGTnHPHcXdB8KWfhyaZ7C6vnWdnkkinuDIrSO25pMH+Inv7mrmsaJZa5bxR3qMHgkE0E0bbZIXHRkYcg9vcEg5BxQBx2paleR6r4g8IvqFxKi6H/AGhDe4QyxZZkaJiVKnO0EZGcFuehGv8ADS2lg+HGhNLf3F4JdOt3QTLGBCPKX5F2KuVH+1k+pNWYfBenQ2uoIZryW61IKLu+kmzPIo6Lux8q442gAcnjmr+g6HbeHdKj06wkna1iwIkmk3+WoAAUH0GP1NAHJaU2t6l8QfFujyeJL5bWwjtXttsUG6Myo7EZ8voCB7nAyTznCh8V+Ida8IeH7xNVls719cGkXjW0cRinG9lMo3ITnCggAgdRg9tKw0TUNR+JniO/uLTW9IttRjtora9gljTKxowcMNzY3fLg7dw7Fc10s3gPRpLDT7G3+02dpppD2sNtOVVHBJEncl8k8n1NMDA1nWNf0PWtC8MNdXmqzagLqaS7tIYIbho05SNfMYR5Ab5m6kL05qGbX/Ftpb6do2oCSwutU1lrO3v5/JeZbXZ5gYqhMfm9V9OM4NdnqXhqy1W1so7t7g3FgQ1teJKVnjYDBbd3JHUEYOeRVdvBmkyaY1pOLiV2uheG7edjOLgAKsofqGAUAY4wMYxxSA5yytbmD41XVlJqdzOT4bDRXEix+ZFuuCMDC7TgrkZB685FZ0Hi3WrbwXYIb+SXUNS8SPpAv5Y0JhTz3TftACbgqYAxjJ6V1KeALJddOtHVdXbUntvsslz9rwZEyTyoAUYJ6AAZAOM5Jli8A6Kmk3OmOLqa0uJhcBJJ2Jhm3l/MjYYKtuYnIP6cUAc7410fXLDwB4t+0+JLqey+yebaYVBOAIz5iSNtwVY4+6FIHGeuW63dahonwaurnTPE122o2FnFcbytsXjDRqBEVEWAnOQcbv8AaxxXXR+E9PNjfW1+9xqJ1CH7PcS3km92iwQEBAAAGSeAOST15qm3gDSJfD0ujXEt7NbXG1bh3uD5k6qmxVZhjgDHAxyATznIBnRavqGt+NX8Nx3s9hbWmkw3clxb7fOlkc4HLqwCgD0yT37VzOp+L9fPg/U5YNUlW90PxANLaVY4wt7H5sYBk+X5Ww2DsK85+g9Ak8I2bx25ju76G8t4zCt9FNidoy27YzYwygngEcdsVWvPh9ol5o0GlYuobSKUzssM5UzS7g3mSN1d9wBye9MDLXVNV0Xx/d6IdUkv7c6DJqSPqBjXZMsoTllVQFIPI6DHGKzvBuvapJ4msNO1+bWrS+kt5Hntr9I3t7qQAHfBLGuMD5vlyBgg4yMnob74eabqF695cahqv2mSzNk8ou+WhONyHIxgkZPHXNX9M8KWumX0FyLy+uhaQmC0iuZt6WyEAELwCxO0fM5ZscZxxSA3KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/2Q==)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vrcL-zNwGJM"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWw-34MhxqYZ"
      },
      "source": [
        "**categorical_crossentropy** is the loss function that’s used as a feedback signal for learning the weight tensors, and which the training phase will attempt to minimize. You also know that this reduction of the loss happens via minibatch stochastic gradient descent. The exact rules governing a specific use of gradient descent are defined by the **rmsprop optimizer** passed as the first argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsD4_gn8xA45"
      },
      "source": [
        "#We also need to categorically encode the labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWl0ldAyJJgF",
        "outputId": "80c27ec2-8d93-42e3-f972-211e91fa079a"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI60BfndJFWj",
        "outputId": "0ee2db9d-b5b0-4002-9cdd-27f1c4d1a1b7"
      },
      "source": [
        "#one-hot encoding example\n",
        "from numpy import argmax\n",
        "# define example\n",
        "data = [1, 3, 2, 0, 3, 2, 2, 1, 0, 1]\n",
        "print(data)\n",
        "# one hot encode\n",
        "encoded = to_categorical(data)\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 0, 3, 2, 2, 1, 0, 1]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOR17N350OoU"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpFFGIg8DdY2"
      },
      "source": [
        "model.fit(input_tensor, output_tensor, epochs=10, batch_size=128,)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMHUiSlgweLc",
        "outputId": "8eaaea76-e8f0-46d6-fcf5-575879bdb3c4"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 11ms/step - loss: 0.2562 - accuracy: 0.9271\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1026 - accuracy: 0.9705\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.0688 - accuracy: 0.9790\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0500 - accuracy: 0.9847\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0379 - accuracy: 0.9883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2661d9b4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6jtlPc1x122"
      },
      "source": [
        "**When you call fit:** the network will start to iterate on the training data in mini-batches of 128 samples, 5 times over (each iteration over all the training data is called an epoch). \n",
        "\n",
        "At each iteration, the network will compute the gradients of the weights with regard to the loss on the batch, and update the weights accordingly. After these 5 epochs, the network will have performed 2,345 gradient updates (469 per epoch), and the loss of the network will be sufficiently low that the network will be capable of classifying handwritten digits with high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrrpmmIq0Q6I"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh3CvikmxD3G",
        "outputId": "bd356180-e36e-4c55-a94f-0187696d777c"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9789\n",
            "test_acc: 0.9789000153541565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31xGwfqQ0pes"
      },
      "source": [
        "This gap between training accuracy and test accuracy is an example of\n",
        "overfitting: the fact that machine-learning models tend to perform worse on new data than on their training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8CTWlXY12O4"
      },
      "source": [
        "#**Classification Exercise with Fashion MNIST Dataset** : \n",
        "- Load the Fashion MNIST Dataset\n",
        "- Check the shapes for x_train, y_train, x_test, y_test\n",
        "- Plot one example from training data\n",
        "- Reshape it and scale it to the [0,1] x_train and x_test\n",
        "- Create the model\n",
        "- Compile the model\n",
        "- One hot encode target values y_train and y_test (using to_categorical) \n",
        "- Train and Evaluate according to test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qodR78ht2DNm"
      },
      "source": [
        "#Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQbIZ5gpAhFO",
        "outputId": "7dd01260-419d-43b3-e6ae-0df6e41f5396"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbwLAGVj2YLF",
        "outputId": "bd9f2f43-84bf-441f-c9e2-ac565444f016"
      },
      "source": [
        "#Check the shapes\n",
        "print('X train=%s y train=%s' % (x_train.shape,y_train.shape))\n",
        "print('X test=%s y test=%s' % (x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train=(60000, 28, 28) y train=(60000,)\n",
            "X test=(10000, 28, 28) y test=(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "F49V1e-v2Zm9",
        "outputId": "92861b93-241f-46b8-e563-1f02be706750"
      },
      "source": [
        "#Plot the one image from training data\n",
        "example = x_train[22]\n",
        "\n",
        "plt.imshow(example, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAwRkeQC7KY-"
      },
      "source": [
        "We know that the pixel values for each image in the dataset are unsigned integers in the range between black and white, or 0 and 255.\n",
        "\n",
        "A good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q98h0_UU8BYG"
      },
      "source": [
        "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the training set and the testing set be preprocessed in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuwV9nep3Lrb"
      },
      "source": [
        "#Reshape and scaling images (x_train,x_test)\n",
        "x_train = x_train.reshape((60000, 28 * 28))\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.reshape((10000, 28 * 28))\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmZlMLy2g6B"
      },
      "source": [
        "#Creating a model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV87RRrp3Suu"
      },
      "source": [
        "#Compilation \n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QysQM2Ii3Wvx"
      },
      "source": [
        "#We also need to categorically encode the labels \n",
        "# to one hot encode target values\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ojMNaj3Y97",
        "outputId": "27f6dc78-f171-4e7c-c857-1068ae84af1b"
      },
      "source": [
        "#Train the model\n",
        "model.fit(x_train,y_train, epochs=5,batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 11ms/step - loss: 0.5598 - accuracy: 0.7997\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3795 - accuracy: 0.8608\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3368 - accuracy: 0.8757\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3118 - accuracy: 0.8852\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2918 - accuracy: 0.8925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f265a4195d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O50s2Mch3a07",
        "outputId": "7532d942-e01e-4407-9b84-2edb10c14e45"
      },
      "source": [
        "#Evalaute the model\n",
        "test_loss2, test_acc2 = model.evaluate(x_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3582 - accuracy: 0.8738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw6AYqYYDhh3",
        "outputId": "6e3a83ed-5f8d-4e8d-8b72-edc5e122f178"
      },
      "source": [
        "test_loss2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3581920564174652"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBn9_wKDDkZp",
        "outputId": "43a9c8ee-2536-4a2f-b323-cc36c665814c"
      },
      "source": [
        "test_acc2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8737999796867371"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}